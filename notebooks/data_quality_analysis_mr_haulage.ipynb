{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Mr Haulage - Fleet Analysis - Data Cleaning & Initial Inspection\n",
    "## Author: Lottie Jane Pollard\n",
    "\n",
    "*\"Garbage in, Garbage out\" - George Fuechsel, IBM*"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Business Case Analysis Brief:\n",
    "\n",
    "Mr Haulage runs a box delivery firm that has been in his family for generations. They run a contract with Defense to deliver supplies within the UK. His old fleet of vehicles to service this contract are starting to show their age, and he wants to replace his current trucks with some new ones.  The firm gets two types of boxes to transport; a small box and a large box. The prices paid by the customer are shown below:\n",
    "\n",
    "\n",
    "<img src=\"/Users/lottiejanepollare/Library/Mobile Documents/com~apple~CloudDocs/CV, Profiles, Interviews & Job Applications/applications/techmodal_analyst_data_engineer/20230825_Analyst_case_study_submission_Lottie_Jane_Pollard/images/table_1_delivery-payments.png\" alt=\"table_1_delivery-payments\" width=\"350\"/>\n",
    "\n",
    "\n",
    "The manager of the firm is deciding on how many trucks to buy to transport these boxes. There are two types of trucks on the market; both types can perform one delivery per day:\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"/Users/lottiejanepollare/Library/Mobile Documents/com~apple~CloudDocs/CV, Profiles, Interviews & Job Applications/applications/techmodal_analyst_data_engineer/20230825_Analyst_case_study_submission_Lottie_Jane_Pollard/images/table_2_truck_details.png\" alt=\"table_2_truck_details.png\" width=\"1000\"/>\n",
    "\n",
    "\n",
    "Mr Haulage has provided access to a dataset for about two years’ worth of orders.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Challenge:\n",
    "\n",
    "What should Mr Haulage buy to replace his fleet?\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Assumptions:\n",
    "\n",
    "I will list the assumptions that my recommendations will be based on here as I go:\n",
    "\n",
    "- Assume all customer_id's are pertaining to the single defense contract in question\n",
    "- Assume item_serial is allowed duplicate values. There are 18 duplicate values, close to unique per order, however, order dates & delivery regions are different, so I have assumed duplicates to be allowed in this context."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Questions for Mr Haulage & his Management Team:\n",
    "\n",
    "- I'd like to clarify with business that all records in this dataset pertain to the ONE defense contract in question? There are 1,792 customers in the dataset of 2,000 orders indicating a lack of repeat business, I'd expect to see fewer customer_id's & more repeat orders when analysing one specific contract. I am working on the assumption that the singular aforementioned 'Defense Contract' is made up of many customers, therefore validating many Customer ID's. However, I'd like to clarify this with Mr Haulage.\n",
    "- Could you clarify the meaning of item_serial? I have checked as best I can for duplicate data here, but without a further context I can only assume its value & allow duplicates. Considering there are 2,000 orders & 1,982 item serials (only a variation of 18); it strikes me that there is the potential for there to be duplicate records placed by the Defense contractor accidentally, maybe two order_id’s / purchase orders raised for the same delivery that may not have been fulfilled or made it to invoicing.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Initial Inspection:\n",
    "\n",
    "I'll perform an initial inspection of the dataset to begin with"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-08-30T19:59:35.123235Z",
     "start_time": "2023-08-30T19:59:35.054251Z"
    }
   },
   "outputs": [],
   "source": [
    "# libraries to import\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "    Order ID  Customer ID  Order Date Order Time  Item Serial Box Type  \\\n0    1097342       733603  22/08/2021      00:14        30351    Small   \n1    1097343       405061  22/08/2021      07:08        17634    Small   \n2    1097344       842139  22/08/2021      10:15        25598    Small   \n3    1097345       211806  22/08/2021      17:05        10104    Small   \n4    1097346       103222  22/08/2021      23:48         3252    Small   \n5    1097347       603400  22/08/2021      23:57        62831    Small   \n6    1097348       837737  23/08/2021      02:11        90766    Large   \n7    1097349       334749  23/08/2021      04:43        93186    Large   \n8    1097350       239710  23/08/2021      11:49        99590    Large   \n9    1097351       730371  23/08/2021      14:03        39952    Small   \n10   1097352       870782  23/08/2021      19:03        20624    Small   \n11   1097353       697945  23/08/2021      20:34        23747    Small   \n12   1097354       862722  23/08/2021      21:56        32892    Small   \n13   1097355       701155  24/08/2021      01:24        92044    Large   \n14   1097356       932823  24/08/2021      04:54         3194    Small   \n15   1097357       569115  24/08/2021      07:20        12419    Small   \n16   1097358       630457  24/08/2021      10:23        21721    Small   \n17   1097359       212427  24/08/2021      12:40        51071    Small   \n18   1097360       326432  24/08/2021      13:13        91003    Large   \n19   1097361       103222  24/08/2021      13:25        17655    Small   \n20   1097362       800908  24/08/2021      18:31        17431    Small   \n21   1097363       899112  24/08/2021      22:17        80954    Large   \n22   1097364       559521  24/08/2021      23:38        11270    Small   \n23   1097365       281402  25/08/2021      01:13        23845    Small   \n24   1097366       322715  25/08/2021      07:41         7180    Small   \n25   1097367       796456  25/08/2021      12:54        66018    Small   \n26   1097368       988770  25/08/2021      13:17        47086    Small   \n27   1097369       706131  25/08/2021      16:39        85902    Large   \n28   1097370       405990  25/08/2021      21:27        55428    Small   \n29   1097371       378756  25/08/2021      22:02        37832    Small   \n30   1097372       170561  26/08/2021      03:19        84189    Large   \n31   1097373       188318  26/08/2021      07:55        77674    Large   \n32   1097374       892013  26/08/2021      11:23        41953    Small   \n33   1097375       260338  26/08/2021      13:26        24960    Small   \n34   1097376       142521  26/08/2021      21:15        42169    Small   \n35   1097377       261311  26/08/2021      22:10        78409    Large   \n36   1097378       950702  27/08/2021      00:50        19359    Small   \n37   1097379       104011  27/08/2021      07:10        78514    Large   \n38   1097380       458412  27/08/2021      07:30        68757    Small   \n39   1097381       104011  27/08/2021      10:44        33761    Small   \n40   1097382       270488  27/08/2021      17:19        59264    Small   \n41   1097383       979973  27/08/2021      18:05        97018    Large   \n42   1097384       103222  27/08/2021      20:35        69138    Small   \n43   1097385       104011  28/08/2021      02:41        96646    Large   \n44   1097386       617548  28/08/2021      05:53        95223    Large   \n45   1097387       488070  28/08/2021      13:43        37670    Small   \n46   1097388       635746  28/08/2021      17:48        50632    Small   \n47   1097389       636700  28/08/2021      23:06        39555    Small   \n48   1097390       366566  29/08/2021      01:50        23145    Small   \n49   1097391       340083  29/08/2021      05:44        52588    Small   \n\n   Delivery Region  Distance (miles)  \n0       South East                70  \n1   Greater London                32  \n2       South West               190  \n3       South West                85  \n4   Greater London                43  \n5   Greater London                33  \n6    West Midlands               143  \n7   Greater London                45  \n8       North East               210  \n9       South West               110  \n10      South East                72  \n11      South East                67  \n12     South Wales               171  \n13  Greater London                38  \n14     South Wales               244  \n15   West Midlands               159  \n16   East Midlands                83  \n17      South East                76  \n18  Greater London                24  \n19      South East                67  \n20  Greater London                49  \n21      South East                68  \n22      North East               292  \n23   West Midlands               118  \n24      South East                79  \n25   East Midlands               119  \n26     North Wales               210  \n27      South East                44  \n28  Greater London                19  \n29      South East                49  \n30      South East                59  \n31  Greater London                25  \n32   West Midlands               107  \n33   West Midlands               125  \n34  Greater London                13  \n35  Greater London                 5  \n36  Greater London                25  \n37   East Midlands                52  \n38      South East                44  \n39   East Midlands                42  \n40      South West               271  \n41  Greater London                16  \n42      South West               110  \n43   East Midlands                82  \n44  Greater London                32  \n45  Greater London                40  \n46      South West               191  \n47      South West               192  \n48      North East               197  \n49     North Wales               280  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Order ID</th>\n      <th>Customer ID</th>\n      <th>Order Date</th>\n      <th>Order Time</th>\n      <th>Item Serial</th>\n      <th>Box Type</th>\n      <th>Delivery Region</th>\n      <th>Distance (miles)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1097342</td>\n      <td>733603</td>\n      <td>22/08/2021</td>\n      <td>00:14</td>\n      <td>30351</td>\n      <td>Small</td>\n      <td>South East</td>\n      <td>70</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1097343</td>\n      <td>405061</td>\n      <td>22/08/2021</td>\n      <td>07:08</td>\n      <td>17634</td>\n      <td>Small</td>\n      <td>Greater London</td>\n      <td>32</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1097344</td>\n      <td>842139</td>\n      <td>22/08/2021</td>\n      <td>10:15</td>\n      <td>25598</td>\n      <td>Small</td>\n      <td>South West</td>\n      <td>190</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1097345</td>\n      <td>211806</td>\n      <td>22/08/2021</td>\n      <td>17:05</td>\n      <td>10104</td>\n      <td>Small</td>\n      <td>South West</td>\n      <td>85</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1097346</td>\n      <td>103222</td>\n      <td>22/08/2021</td>\n      <td>23:48</td>\n      <td>3252</td>\n      <td>Small</td>\n      <td>Greater London</td>\n      <td>43</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>1097347</td>\n      <td>603400</td>\n      <td>22/08/2021</td>\n      <td>23:57</td>\n      <td>62831</td>\n      <td>Small</td>\n      <td>Greater London</td>\n      <td>33</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>1097348</td>\n      <td>837737</td>\n      <td>23/08/2021</td>\n      <td>02:11</td>\n      <td>90766</td>\n      <td>Large</td>\n      <td>West Midlands</td>\n      <td>143</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>1097349</td>\n      <td>334749</td>\n      <td>23/08/2021</td>\n      <td>04:43</td>\n      <td>93186</td>\n      <td>Large</td>\n      <td>Greater London</td>\n      <td>45</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>1097350</td>\n      <td>239710</td>\n      <td>23/08/2021</td>\n      <td>11:49</td>\n      <td>99590</td>\n      <td>Large</td>\n      <td>North East</td>\n      <td>210</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>1097351</td>\n      <td>730371</td>\n      <td>23/08/2021</td>\n      <td>14:03</td>\n      <td>39952</td>\n      <td>Small</td>\n      <td>South West</td>\n      <td>110</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>1097352</td>\n      <td>870782</td>\n      <td>23/08/2021</td>\n      <td>19:03</td>\n      <td>20624</td>\n      <td>Small</td>\n      <td>South East</td>\n      <td>72</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>1097353</td>\n      <td>697945</td>\n      <td>23/08/2021</td>\n      <td>20:34</td>\n      <td>23747</td>\n      <td>Small</td>\n      <td>South East</td>\n      <td>67</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>1097354</td>\n      <td>862722</td>\n      <td>23/08/2021</td>\n      <td>21:56</td>\n      <td>32892</td>\n      <td>Small</td>\n      <td>South Wales</td>\n      <td>171</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>1097355</td>\n      <td>701155</td>\n      <td>24/08/2021</td>\n      <td>01:24</td>\n      <td>92044</td>\n      <td>Large</td>\n      <td>Greater London</td>\n      <td>38</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>1097356</td>\n      <td>932823</td>\n      <td>24/08/2021</td>\n      <td>04:54</td>\n      <td>3194</td>\n      <td>Small</td>\n      <td>South Wales</td>\n      <td>244</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>1097357</td>\n      <td>569115</td>\n      <td>24/08/2021</td>\n      <td>07:20</td>\n      <td>12419</td>\n      <td>Small</td>\n      <td>West Midlands</td>\n      <td>159</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>1097358</td>\n      <td>630457</td>\n      <td>24/08/2021</td>\n      <td>10:23</td>\n      <td>21721</td>\n      <td>Small</td>\n      <td>East Midlands</td>\n      <td>83</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>1097359</td>\n      <td>212427</td>\n      <td>24/08/2021</td>\n      <td>12:40</td>\n      <td>51071</td>\n      <td>Small</td>\n      <td>South East</td>\n      <td>76</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>1097360</td>\n      <td>326432</td>\n      <td>24/08/2021</td>\n      <td>13:13</td>\n      <td>91003</td>\n      <td>Large</td>\n      <td>Greater London</td>\n      <td>24</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>1097361</td>\n      <td>103222</td>\n      <td>24/08/2021</td>\n      <td>13:25</td>\n      <td>17655</td>\n      <td>Small</td>\n      <td>South East</td>\n      <td>67</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>1097362</td>\n      <td>800908</td>\n      <td>24/08/2021</td>\n      <td>18:31</td>\n      <td>17431</td>\n      <td>Small</td>\n      <td>Greater London</td>\n      <td>49</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>1097363</td>\n      <td>899112</td>\n      <td>24/08/2021</td>\n      <td>22:17</td>\n      <td>80954</td>\n      <td>Large</td>\n      <td>South East</td>\n      <td>68</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>1097364</td>\n      <td>559521</td>\n      <td>24/08/2021</td>\n      <td>23:38</td>\n      <td>11270</td>\n      <td>Small</td>\n      <td>North East</td>\n      <td>292</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>1097365</td>\n      <td>281402</td>\n      <td>25/08/2021</td>\n      <td>01:13</td>\n      <td>23845</td>\n      <td>Small</td>\n      <td>West Midlands</td>\n      <td>118</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>1097366</td>\n      <td>322715</td>\n      <td>25/08/2021</td>\n      <td>07:41</td>\n      <td>7180</td>\n      <td>Small</td>\n      <td>South East</td>\n      <td>79</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>1097367</td>\n      <td>796456</td>\n      <td>25/08/2021</td>\n      <td>12:54</td>\n      <td>66018</td>\n      <td>Small</td>\n      <td>East Midlands</td>\n      <td>119</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>1097368</td>\n      <td>988770</td>\n      <td>25/08/2021</td>\n      <td>13:17</td>\n      <td>47086</td>\n      <td>Small</td>\n      <td>North Wales</td>\n      <td>210</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>1097369</td>\n      <td>706131</td>\n      <td>25/08/2021</td>\n      <td>16:39</td>\n      <td>85902</td>\n      <td>Large</td>\n      <td>South East</td>\n      <td>44</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>1097370</td>\n      <td>405990</td>\n      <td>25/08/2021</td>\n      <td>21:27</td>\n      <td>55428</td>\n      <td>Small</td>\n      <td>Greater London</td>\n      <td>19</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>1097371</td>\n      <td>378756</td>\n      <td>25/08/2021</td>\n      <td>22:02</td>\n      <td>37832</td>\n      <td>Small</td>\n      <td>South East</td>\n      <td>49</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>1097372</td>\n      <td>170561</td>\n      <td>26/08/2021</td>\n      <td>03:19</td>\n      <td>84189</td>\n      <td>Large</td>\n      <td>South East</td>\n      <td>59</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>1097373</td>\n      <td>188318</td>\n      <td>26/08/2021</td>\n      <td>07:55</td>\n      <td>77674</td>\n      <td>Large</td>\n      <td>Greater London</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>1097374</td>\n      <td>892013</td>\n      <td>26/08/2021</td>\n      <td>11:23</td>\n      <td>41953</td>\n      <td>Small</td>\n      <td>West Midlands</td>\n      <td>107</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>1097375</td>\n      <td>260338</td>\n      <td>26/08/2021</td>\n      <td>13:26</td>\n      <td>24960</td>\n      <td>Small</td>\n      <td>West Midlands</td>\n      <td>125</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>1097376</td>\n      <td>142521</td>\n      <td>26/08/2021</td>\n      <td>21:15</td>\n      <td>42169</td>\n      <td>Small</td>\n      <td>Greater London</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>1097377</td>\n      <td>261311</td>\n      <td>26/08/2021</td>\n      <td>22:10</td>\n      <td>78409</td>\n      <td>Large</td>\n      <td>Greater London</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>1097378</td>\n      <td>950702</td>\n      <td>27/08/2021</td>\n      <td>00:50</td>\n      <td>19359</td>\n      <td>Small</td>\n      <td>Greater London</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>1097379</td>\n      <td>104011</td>\n      <td>27/08/2021</td>\n      <td>07:10</td>\n      <td>78514</td>\n      <td>Large</td>\n      <td>East Midlands</td>\n      <td>52</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>1097380</td>\n      <td>458412</td>\n      <td>27/08/2021</td>\n      <td>07:30</td>\n      <td>68757</td>\n      <td>Small</td>\n      <td>South East</td>\n      <td>44</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>1097381</td>\n      <td>104011</td>\n      <td>27/08/2021</td>\n      <td>10:44</td>\n      <td>33761</td>\n      <td>Small</td>\n      <td>East Midlands</td>\n      <td>42</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>1097382</td>\n      <td>270488</td>\n      <td>27/08/2021</td>\n      <td>17:19</td>\n      <td>59264</td>\n      <td>Small</td>\n      <td>South West</td>\n      <td>271</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>1097383</td>\n      <td>979973</td>\n      <td>27/08/2021</td>\n      <td>18:05</td>\n      <td>97018</td>\n      <td>Large</td>\n      <td>Greater London</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>1097384</td>\n      <td>103222</td>\n      <td>27/08/2021</td>\n      <td>20:35</td>\n      <td>69138</td>\n      <td>Small</td>\n      <td>South West</td>\n      <td>110</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>1097385</td>\n      <td>104011</td>\n      <td>28/08/2021</td>\n      <td>02:41</td>\n      <td>96646</td>\n      <td>Large</td>\n      <td>East Midlands</td>\n      <td>82</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>1097386</td>\n      <td>617548</td>\n      <td>28/08/2021</td>\n      <td>05:53</td>\n      <td>95223</td>\n      <td>Large</td>\n      <td>Greater London</td>\n      <td>32</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>1097387</td>\n      <td>488070</td>\n      <td>28/08/2021</td>\n      <td>13:43</td>\n      <td>37670</td>\n      <td>Small</td>\n      <td>Greater London</td>\n      <td>40</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>1097388</td>\n      <td>635746</td>\n      <td>28/08/2021</td>\n      <td>17:48</td>\n      <td>50632</td>\n      <td>Small</td>\n      <td>South West</td>\n      <td>191</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>1097389</td>\n      <td>636700</td>\n      <td>28/08/2021</td>\n      <td>23:06</td>\n      <td>39555</td>\n      <td>Small</td>\n      <td>South West</td>\n      <td>192</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>1097390</td>\n      <td>366566</td>\n      <td>29/08/2021</td>\n      <td>01:50</td>\n      <td>23145</td>\n      <td>Small</td>\n      <td>North East</td>\n      <td>197</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>1097391</td>\n      <td>340083</td>\n      <td>29/08/2021</td>\n      <td>05:44</td>\n      <td>52588</td>\n      <td>Small</td>\n      <td>North Wales</td>\n      <td>280</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NB: dataset naming convention 'df' will be used for the initial quality analysis & data cleansing\n",
    "\n",
    "# import dataset provided by Mr Haulage\n",
    "df = pd.read_excel('/Users/lottiejanepollare/Library/Mobile Documents/com~apple~CloudDocs/CV, Profiles, Interviews & Job Applications/applications/techmodal_analyst_data_engineer/20230825_Analyst_case_study_submission_Lottie_Jane_Pollard/datasets/mr_haulage_order_details.xlsx')\n",
    "\n",
    "# configure display settings: display all columns regardless of df width, disable wrapping columns to display entire field, no truncating columns, display an English date format\n",
    "pd.set_option('display.max.columns', None, 'display.width', None, 'display.max.colwidth', None, 'display.date_dayfirst', True)\n",
    "# this should update the date format displayed for the whole notebook, but it isn't & I'm not sure why - maybe as I'm in Pycharm IDE note JupyterNotebooks itself\n",
    "\n",
    "# show the head of df to see what I'm working with\n",
    "df.head(50)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-30T19:59:35.504529Z",
     "start_time": "2023-08-30T19:59:35.060696Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset has 2000 rows & 8 columns\n"
     ]
    }
   ],
   "source": [
    "# let's check the size of the dataset\n",
    "print(f\"The dataset has {df.shape[0]} rows & {df.shape[1]} columns\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-30T19:59:35.508347Z",
     "start_time": "2023-08-30T19:59:35.504930Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset has been examined for missing or null values, and it has been confirmed that all columns contain complete data. Therefore, further investigation into missing values is not necessary at this time.\n"
     ]
    },
    {
     "data": {
      "text/plain": "Order ID            0\nCustomer ID         0\nOrder Date          0\nOrder Time          0\nItem Serial         0\nBox Type            0\nDelivery Region     0\nDistance (miles)    0\ndtype: int64"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's check the completeness of the dataset by checking for missing or null values\n",
    "null_values = df.isnull().sum()\n",
    "\n",
    "print(f\"The dataset has been examined for missing or null values, and it has been confirmed that all columns contain complete data. Therefore, further investigation into missing values is not necessary at this time.\")\n",
    "\n",
    "null_values"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-30T19:59:35.515934Z",
     "start_time": "2023-08-30T19:59:35.511756Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The list of new column names are:\n",
      "['order_id', 'customer_id', 'order_date', 'order_time', 'item_serial', 'box_type', 'delivery_region', 'distance_(miles)']\n"
     ]
    }
   ],
   "source": [
    "# let's convert column names to lowercase & replace whitespace with underscores for uniformity\n",
    "df.columns = df.columns.str.lower().str.replace(' ', '_')\n",
    "\n",
    "# let's store the column names to a list to access later\n",
    "columns = df.columns.tolist()\n",
    "print(f\"The list of new column names are:\\n{columns}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-30T19:59:35.522353Z",
     "start_time": "2023-08-30T19:59:35.519433Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2000 unique values in order_id\n",
      "--------------------------\n",
      "There are 1792 unique values in customer_id\n",
      "--------------------------\n",
      "There are 597 unique values in order_date\n",
      "--------------------------\n",
      "There are 1083 unique values in order_time\n",
      "--------------------------\n",
      "There are 1982 unique values in item_serial\n",
      "--------------------------\n",
      "There are 2 unique values in box_type\n",
      "--------------------------\n",
      "There are 8 unique values in delivery_region\n",
      "--------------------------\n",
      "There are 289 unique values in distance_(miles)\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "# let's check for unique values & the potential for duplicate information\n",
    "\n",
    "messages = []\n",
    "for col in columns:\n",
    "    unique_count = df[col].nunique()\n",
    "    messages.append(f\"There are {unique_count} unique values in {col}\")\n",
    "\n",
    "for message in messages:\n",
    "    print(message)\n",
    "    print(f\"--------------------------\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-30T19:59:35.569859Z",
     "start_time": "2023-08-30T19:59:35.524770Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Observations:\n",
    "- 2,000 unique order_id's & 2,000 rows in the dataset mean we don't have any duplicate order numbers, therefore negating the need to drop any specific records from the dataset at this stage. This also identifies the 'order_id' as a unique identifier / primary key & will be used as such throughout\n",
    "- 1,792 unique customers out of 2,000 orders tell me there isn't much repeat business. I'd like to clarify with business that all records in this dataset pertain to the ONE defense contract in question\n",
    "- 1,982 unique item_serial values. I'd like to clarify the meaning of this column to better understand its relevance to the business. Potential for duplicate data here that will need investigating.\n",
    "- 2 unique values in box type as expected, small & large\n",
    "- 8 unique delivery regions, I will check these for spelling to confirm no duplicates here"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "order_id             int64\ncustomer_id          int64\norder_date          object\norder_time          object\nitem_serial          int64\nbox_type            object\ndelivery_region     object\ndistance_(miles)     int64\ndtype: object"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's check the current data type of each column\n",
    "df.dtypes"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-30T19:59:35.590260Z",
     "start_time": "2023-08-30T19:59:35.534571Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can see that:\n",
    "\n",
    "- order_id, customer_id, item_serial & distance_(miles) are correct at 'int64' objects\n",
    "- order_date & order_time can be converted to pandas 'datetime64' objects\n",
    "- box_type & delivery_region can be converted to 'category' objects for optimal memory efficiency (even though the dataset is relatively small, 2 box_type categories & 8 delivery_region categories is more efficient than 2 x 2,000 strings)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "order_id                     int64\ncustomer_id                  int64\norder_date          datetime64[ns]\norder_time                  object\nitem_serial                  int64\nbox_type                  category\ndelivery_region           category\ndistance_(miles)             int64\ndtype: object"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first, I'll apply a lambda function to 'box_type' & 'delivery_region' columns to convert the object to lowercase & replace whitespace with underscores for uniformity\n",
    "df[['box_type', 'delivery_region']] = df[['box_type', 'delivery_region']].apply(lambda x: x.str.lower().str.replace(' ', '_'))\n",
    "\n",
    "# I'll also convert them in to 'category' datatypes\n",
    "df['box_type'] = df['box_type'].astype('category')\n",
    "df['delivery_region'] = df['delivery_region'].astype('category')\n",
    "\n",
    "# let's convert 'order_date' to datetime64 datatype\n",
    "df['order_date'] = pd.to_datetime(df['order_date'], format='%d/%m/%Y')\n",
    "\n",
    "# let's convert 'order_time' to datetime using Python's datetime.time to extract only the time itself as an object\n",
    "df['order_time'] = pd.to_datetime(df['order_time'], format='%H:%M').dt.time\n",
    "\n",
    "# check the new data types\n",
    "df.dtypes"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-30T19:59:35.590818Z",
     "start_time": "2023-08-30T19:59:35.549754Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Let's add in some extra columns to allow for financial analysis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# let's create 'week_number', 'order_month', 'order_year' & 'order_quarter' columns based on 'order_date' column\n",
    "\n",
    "# financial week\n",
    "df['order_week'] = df['order_date'].dt.isocalendar().week\n",
    "\n",
    "# financial month\n",
    "df['order_month'] = df['order_date'].dt.strftime('%B')\n",
    "\n",
    "# financial year\n",
    "df['order_year'] = df['order_date'].dt.year\n",
    "\n",
    "# financial quarter (assuming financial year 1st Jan - 3st Dec)\n",
    "df['financial_quarter'] = df['order_date'].dt.month.apply(\n",
    "    lambda x: 'Q1' if 1 <= x <= 3 else 'Q2' if 4 <= x <= 6 else 'Q3' if 7 <= x <= 9 else 'Q4'\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-30T19:59:35.630192Z",
     "start_time": "2023-08-30T19:59:35.571299Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Let's sort the dataset by order_date ascending & find out the time period we are working with"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset contains orders between 22/08/2021 and 10/04/2023\n",
      "The dataset contains orders spanning 596 days.\n"
     ]
    },
    {
     "data": {
      "text/plain": "      order_id  customer_id order_date order_time  item_serial box_type  \\\n0      1097342       733603 2021-08-22   00:14:00        30351    small   \n1      1097343       405061 2021-08-22   07:08:00        17634    small   \n2      1097344       842139 2021-08-22   10:15:00        25598    small   \n3      1097345       211806 2021-08-22   17:05:00        10104    small   \n4      1097346       103222 2021-08-22   23:48:00         3252    small   \n...        ...          ...        ...        ...          ...      ...   \n1993   1099335       216509 2023-04-09   06:40:00         4716    small   \n1997   1099339       710623 2023-04-10   11:32:00          387    small   \n1998   1099340       932977 2023-04-10   17:54:00        80608    large   \n1996   1099338       103222 2023-04-10   01:02:00        29091    small   \n1999   1099341       237989 2023-04-10   21:23:00        34860    small   \n\n     delivery_region  distance_(miles)  order_week order_month  order_year  \\\n0         south_east                70          33      August        2021   \n1     greater_london                32          33      August        2021   \n2         south_west               190          33      August        2021   \n3         south_west                85          33      August        2021   \n4     greater_london                43          33      August        2021   \n...              ...               ...         ...         ...         ...   \n1993  greater_london                 8          14       April        2023   \n1997      south_west               300          15       April        2023   \n1998      south_east                48          15       April        2023   \n1996      south_west               233          15       April        2023   \n1999  greater_london                10          15       April        2023   \n\n     financial_quarter  \n0                   Q3  \n1                   Q3  \n2                   Q3  \n3                   Q3  \n4                   Q3  \n...                ...  \n1993                Q2  \n1997                Q2  \n1998                Q2  \n1996                Q2  \n1999                Q2  \n\n[2000 rows x 12 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>order_id</th>\n      <th>customer_id</th>\n      <th>order_date</th>\n      <th>order_time</th>\n      <th>item_serial</th>\n      <th>box_type</th>\n      <th>delivery_region</th>\n      <th>distance_(miles)</th>\n      <th>order_week</th>\n      <th>order_month</th>\n      <th>order_year</th>\n      <th>financial_quarter</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1097342</td>\n      <td>733603</td>\n      <td>2021-08-22</td>\n      <td>00:14:00</td>\n      <td>30351</td>\n      <td>small</td>\n      <td>south_east</td>\n      <td>70</td>\n      <td>33</td>\n      <td>August</td>\n      <td>2021</td>\n      <td>Q3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1097343</td>\n      <td>405061</td>\n      <td>2021-08-22</td>\n      <td>07:08:00</td>\n      <td>17634</td>\n      <td>small</td>\n      <td>greater_london</td>\n      <td>32</td>\n      <td>33</td>\n      <td>August</td>\n      <td>2021</td>\n      <td>Q3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1097344</td>\n      <td>842139</td>\n      <td>2021-08-22</td>\n      <td>10:15:00</td>\n      <td>25598</td>\n      <td>small</td>\n      <td>south_west</td>\n      <td>190</td>\n      <td>33</td>\n      <td>August</td>\n      <td>2021</td>\n      <td>Q3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1097345</td>\n      <td>211806</td>\n      <td>2021-08-22</td>\n      <td>17:05:00</td>\n      <td>10104</td>\n      <td>small</td>\n      <td>south_west</td>\n      <td>85</td>\n      <td>33</td>\n      <td>August</td>\n      <td>2021</td>\n      <td>Q3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1097346</td>\n      <td>103222</td>\n      <td>2021-08-22</td>\n      <td>23:48:00</td>\n      <td>3252</td>\n      <td>small</td>\n      <td>greater_london</td>\n      <td>43</td>\n      <td>33</td>\n      <td>August</td>\n      <td>2021</td>\n      <td>Q3</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1993</th>\n      <td>1099335</td>\n      <td>216509</td>\n      <td>2023-04-09</td>\n      <td>06:40:00</td>\n      <td>4716</td>\n      <td>small</td>\n      <td>greater_london</td>\n      <td>8</td>\n      <td>14</td>\n      <td>April</td>\n      <td>2023</td>\n      <td>Q2</td>\n    </tr>\n    <tr>\n      <th>1997</th>\n      <td>1099339</td>\n      <td>710623</td>\n      <td>2023-04-10</td>\n      <td>11:32:00</td>\n      <td>387</td>\n      <td>small</td>\n      <td>south_west</td>\n      <td>300</td>\n      <td>15</td>\n      <td>April</td>\n      <td>2023</td>\n      <td>Q2</td>\n    </tr>\n    <tr>\n      <th>1998</th>\n      <td>1099340</td>\n      <td>932977</td>\n      <td>2023-04-10</td>\n      <td>17:54:00</td>\n      <td>80608</td>\n      <td>large</td>\n      <td>south_east</td>\n      <td>48</td>\n      <td>15</td>\n      <td>April</td>\n      <td>2023</td>\n      <td>Q2</td>\n    </tr>\n    <tr>\n      <th>1996</th>\n      <td>1099338</td>\n      <td>103222</td>\n      <td>2023-04-10</td>\n      <td>01:02:00</td>\n      <td>29091</td>\n      <td>small</td>\n      <td>south_west</td>\n      <td>233</td>\n      <td>15</td>\n      <td>April</td>\n      <td>2023</td>\n      <td>Q2</td>\n    </tr>\n    <tr>\n      <th>1999</th>\n      <td>1099341</td>\n      <td>237989</td>\n      <td>2023-04-10</td>\n      <td>21:23:00</td>\n      <td>34860</td>\n      <td>small</td>\n      <td>greater_london</td>\n      <td>10</td>\n      <td>15</td>\n      <td>April</td>\n      <td>2023</td>\n      <td>Q2</td>\n    </tr>\n  </tbody>\n</table>\n<p>2000 rows × 12 columns</p>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sort the dataset by order_date ascending\n",
    "df = df.sort_values(by='order_date', ascending=True)\n",
    "\n",
    "# get the earliest & latest dates in the dataset\n",
    "earliest_order_date = df['order_date'].iloc[0]\n",
    "latest_order_date = df['order_date'].iloc[-1]\n",
    "\n",
    "# calculate the number of days the dataset spans\n",
    "no_of_days_data = (latest_order_date - earliest_order_date).days\n",
    "\n",
    "# format the date\n",
    "formatted_earliest = earliest_order_date.strftime('%d/%m/%Y')\n",
    "formatted_latest = latest_order_date.strftime('%d/%m/%Y')\n",
    "\n",
    "print(f\"The dataset contains orders between {formatted_earliest} and {formatted_latest}\")\n",
    "print(f\"The dataset contains orders spanning {no_of_days_data} days.\")\n",
    "\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-30T19:59:35.663404Z",
     "start_time": "2023-08-30T19:59:35.589944Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Considering there are 2,000 orders & 1,982 item serials (only a variation of 18); it strikes me that there is the potential for there to be duplicate records placed by the Defense contractor accidentally, maybe two order_id's / purchase orders raised for the same delivery that may not have been fulfilled or made it to invoicing. I will perform an extra check to ensure as best I can the dataset does not contain duplicate records. I will also ask Mr Haulage for clarification.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 rows with matching customer_id, order_date & item_serial. We can confirm there are definitely no duplicate records\n"
     ]
    }
   ],
   "source": [
    "# let's do an extra check to make sure there aren't any records with the same customer_id, order_date & item_serial\n",
    "duplicates = df[df.duplicated(subset=['customer_id', 'order_date', 'item_serial'], keep=False)]\n",
    "\n",
    "# check the size of the dataset\n",
    "print(f\"There are {duplicates.shape[0]} rows with matching customer_id, order_date & item_serial. We can confirm there are definitely no duplicate records\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-30T19:59:35.663643Z",
     "start_time": "2023-08-30T19:59:35.612044Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's check the delivery regions do not contain spelling mistakes & therefore potential duplicates"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I can see that the 8 unique regions are real-world unique regions\n"
     ]
    },
    {
     "data": {
      "text/plain": "['east_midlands',\n 'greater_london',\n 'north_east',\n 'north_wales',\n 'south_east',\n 'south_wales',\n 'south_west',\n 'west_midlands']"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the delivery regions didn't contain spelling mistakes which could lead to duplicate data; however, the 8 unique regions are all different & verified regions of the UK\n",
    "unique_regions = list(df['delivery_region'].unique().sort_values())\n",
    "\n",
    "print(f\"I can see that the {len(unique_regions)} unique regions are real-world unique regions\")\n",
    "\n",
    "unique_regions"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-30T19:59:35.663850Z",
     "start_time": "2023-08-30T19:59:35.621592Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Let's start our cost analysis by adding a column for revenue per box to allow for some Pandas aggregation & visualisations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "      order_id  customer_id order_date order_time  order_revenue  item_serial  \\\n0      1097342       733603 2021-08-22   00:14:00          20.00        30351   \n1      1097343       405061 2021-08-22   07:08:00          20.00        17634   \n2      1097344       842139 2021-08-22   10:15:00          20.00        25598   \n3      1097345       211806 2021-08-22   17:05:00          20.00        10104   \n4      1097346       103222 2021-08-22   23:48:00          20.00         3252   \n...        ...          ...        ...        ...            ...          ...   \n1993   1099335       216509 2023-04-09   06:40:00          20.00         4716   \n1997   1099339       710623 2023-04-10   11:32:00          20.00          387   \n1998   1099340       932977 2023-04-10   17:54:00         100.00        80608   \n1996   1099338       103222 2023-04-10   01:02:00          20.00        29091   \n1999   1099341       237989 2023-04-10   21:23:00          20.00        34860   \n\n     box_type delivery_region  distance_(miles)  order_week order_month  \\\n0       small      south_east                70          33      August   \n1       small  greater_london                32          33      August   \n2       small      south_west               190          33      August   \n3       small      south_west                85          33      August   \n4       small  greater_london                43          33      August   \n...       ...             ...               ...         ...         ...   \n1993    small  greater_london                 8          14       April   \n1997    small      south_west               300          15       April   \n1998    large      south_east                48          15       April   \n1996    small      south_west               233          15       April   \n1999    small  greater_london                10          15       April   \n\n      order_year financial_quarter  \n0           2021                Q3  \n1           2021                Q3  \n2           2021                Q3  \n3           2021                Q3  \n4           2021                Q3  \n...          ...               ...  \n1993        2023                Q2  \n1997        2023                Q2  \n1998        2023                Q2  \n1996        2023                Q2  \n1999        2023                Q2  \n\n[2000 rows x 13 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>order_id</th>\n      <th>customer_id</th>\n      <th>order_date</th>\n      <th>order_time</th>\n      <th>order_revenue</th>\n      <th>item_serial</th>\n      <th>box_type</th>\n      <th>delivery_region</th>\n      <th>distance_(miles)</th>\n      <th>order_week</th>\n      <th>order_month</th>\n      <th>order_year</th>\n      <th>financial_quarter</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1097342</td>\n      <td>733603</td>\n      <td>2021-08-22</td>\n      <td>00:14:00</td>\n      <td>20.00</td>\n      <td>30351</td>\n      <td>small</td>\n      <td>south_east</td>\n      <td>70</td>\n      <td>33</td>\n      <td>August</td>\n      <td>2021</td>\n      <td>Q3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1097343</td>\n      <td>405061</td>\n      <td>2021-08-22</td>\n      <td>07:08:00</td>\n      <td>20.00</td>\n      <td>17634</td>\n      <td>small</td>\n      <td>greater_london</td>\n      <td>32</td>\n      <td>33</td>\n      <td>August</td>\n      <td>2021</td>\n      <td>Q3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1097344</td>\n      <td>842139</td>\n      <td>2021-08-22</td>\n      <td>10:15:00</td>\n      <td>20.00</td>\n      <td>25598</td>\n      <td>small</td>\n      <td>south_west</td>\n      <td>190</td>\n      <td>33</td>\n      <td>August</td>\n      <td>2021</td>\n      <td>Q3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1097345</td>\n      <td>211806</td>\n      <td>2021-08-22</td>\n      <td>17:05:00</td>\n      <td>20.00</td>\n      <td>10104</td>\n      <td>small</td>\n      <td>south_west</td>\n      <td>85</td>\n      <td>33</td>\n      <td>August</td>\n      <td>2021</td>\n      <td>Q3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1097346</td>\n      <td>103222</td>\n      <td>2021-08-22</td>\n      <td>23:48:00</td>\n      <td>20.00</td>\n      <td>3252</td>\n      <td>small</td>\n      <td>greater_london</td>\n      <td>43</td>\n      <td>33</td>\n      <td>August</td>\n      <td>2021</td>\n      <td>Q3</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1993</th>\n      <td>1099335</td>\n      <td>216509</td>\n      <td>2023-04-09</td>\n      <td>06:40:00</td>\n      <td>20.00</td>\n      <td>4716</td>\n      <td>small</td>\n      <td>greater_london</td>\n      <td>8</td>\n      <td>14</td>\n      <td>April</td>\n      <td>2023</td>\n      <td>Q2</td>\n    </tr>\n    <tr>\n      <th>1997</th>\n      <td>1099339</td>\n      <td>710623</td>\n      <td>2023-04-10</td>\n      <td>11:32:00</td>\n      <td>20.00</td>\n      <td>387</td>\n      <td>small</td>\n      <td>south_west</td>\n      <td>300</td>\n      <td>15</td>\n      <td>April</td>\n      <td>2023</td>\n      <td>Q2</td>\n    </tr>\n    <tr>\n      <th>1998</th>\n      <td>1099340</td>\n      <td>932977</td>\n      <td>2023-04-10</td>\n      <td>17:54:00</td>\n      <td>100.00</td>\n      <td>80608</td>\n      <td>large</td>\n      <td>south_east</td>\n      <td>48</td>\n      <td>15</td>\n      <td>April</td>\n      <td>2023</td>\n      <td>Q2</td>\n    </tr>\n    <tr>\n      <th>1996</th>\n      <td>1099338</td>\n      <td>103222</td>\n      <td>2023-04-10</td>\n      <td>01:02:00</td>\n      <td>20.00</td>\n      <td>29091</td>\n      <td>small</td>\n      <td>south_west</td>\n      <td>233</td>\n      <td>15</td>\n      <td>April</td>\n      <td>2023</td>\n      <td>Q2</td>\n    </tr>\n    <tr>\n      <th>1999</th>\n      <td>1099341</td>\n      <td>237989</td>\n      <td>2023-04-10</td>\n      <td>21:23:00</td>\n      <td>20.00</td>\n      <td>34860</td>\n      <td>small</td>\n      <td>greater_london</td>\n      <td>10</td>\n      <td>15</td>\n      <td>April</td>\n      <td>2023</td>\n      <td>Q2</td>\n    </tr>\n  </tbody>\n</table>\n<p>2000 rows × 13 columns</p>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first, we will create the values based on if/else criteria (small box = £20 & large box = £100)\n",
    "initial_values = [20.00 if box_type == 'small' else 100.00 if box_type == 'large' else 0 for box_type in df['box_type']]\n",
    "\n",
    "# then, insert a new column with the above initial values, I'll insert the new column, 'order_revenue' after 'item_serial' at column index 4\n",
    "df.insert(loc=4, column='order_revenue', value=initial_values)\n",
    "\n",
    "# set the data type for 'order_revenue' to float64 to accurately represent monetary value\n",
    "df['order_revenue'] = df['order_revenue'].astype('float64')\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-30T19:59:35.672342Z",
     "start_time": "2023-08-30T19:59:35.646252Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### I'm happy with the quality of the dataset as far as is reasonably possible within the given scope. Let's save the dataset to a new, clean csv file.\n",
    "### Sometimes the datatypes don't save with the csv file, so I'll save the metadata for this separately."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The metadata for the column datatypes has been saved to datasets/metadata.xlsx'\n"
     ]
    }
   ],
   "source": [
    "# save data types to dict\n",
    "metadata = df.dtypes.to_dict()\n",
    "\n",
    "# save dict to dataframe\n",
    "metadata_df = pd.DataFrame(list(metadata.items()), columns=['column_name', 'datatype'])\n",
    "\n",
    "# save to excel\n",
    "metadata_df.to_excel('/Users/lottiejanepollare/Library/Mobile Documents/com~apple~CloudDocs/CV, Profiles, Interviews & Job Applications/applications/techmodal_analyst_data_engineer/20230825_Analyst_case_study_submission_Lottie_Jane_Pollard/datasets/metadata.xlsx', index=False)\n",
    "\n",
    "print(f\"The metadata for the column datatypes has been saved to datasets/metadata.xlsx'\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-30T19:59:35.676541Z",
     "start_time": "2023-08-30T19:59:35.655938Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A cleansed version of the dataset 'mr_haulage_order_details.xlsx' has been saved for analysis as 'cleansed_mr_haulage_order_details.csv'\n"
     ]
    }
   ],
   "source": [
    "# let's save the cleansed dataset to a new csv file for further analysis\n",
    "df.to_csv('/Users/lottiejanepollare/Library/Mobile Documents/com~apple~CloudDocs/CV, Profiles, Interviews & Job Applications/applications/techmodal_analyst_data_engineer/20230825_Analyst_case_study_submission_Lottie_Jane_Pollard/datasets/cleansed_mr_haulage_order_details.csv', index=False, sep=',')\n",
    "\n",
    "print(f\"A cleansed version of the dataset 'mr_haulage_order_details.xlsx' has been saved for analysis as 'cleansed_mr_haulage_order_details.csv'\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-30T19:59:35.766437Z",
     "start_time": "2023-08-30T19:59:35.676790Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
